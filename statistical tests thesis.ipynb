{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis Statistical Tests Code\n",
    "Below is all of the code used to run the statistical tests whose results appear in my MA Thesis. \n",
    "\n",
    "## Chi Squared Tests for Distances "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Men and Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2 Statistic: 7.791957436808222, P-value: 0.020323473754362217\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Data: [distances over 7.5 km, distances between 2 and 7.5 km, distances under 2 km]\n",
    "men_counts = [173, 542, 482]\n",
    "women_counts = [132, 488, 515]\n",
    "\n",
    "# Create contingency table\n",
    "contingency_table = np.array([men_counts, women_counts])\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_stat, p_val, dof, ex = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f'Chi2 Statistic: {chi2_stat}, P-value: {p_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residence Chi Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2 Statistic: 328.02925232534125, P-value: 5.879669382717215e-72\n"
     ]
    }
   ],
   "source": [
    "# Data: [distances over 7.5 km, distances between 2 and 7.5 km, distances under 2 km]\n",
    "rural_counts = [294, 522, 333]\n",
    "urban_counts = [36, 565, 705]\n",
    "\n",
    "# Create contingency table\n",
    "contingency_table = np.array([rural_counts, urban_counts])\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_stat, p_val, dof, ex = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f'Chi2 Statistic: {chi2_stat}, P-value: {p_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Chi Squared test for E-bikes and Standard Bikes Distance\n",
    "The weight is 60% for standard and 40% for e-bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2 Statistic: 96.04071997017141, P-value: 1.3964411546656164e-21\n"
     ]
    }
   ],
   "source": [
    "#WEIGHTED CHI2\n",
    "\n",
    "# Data: [distances over 7.5 km, distances between 2 and 7.5 km, distances under 2 km]\n",
    "normal_bike_counts = [144, 585, 725]\n",
    "e_bike_counts = [182, 483, 299]\n",
    "\n",
    "# Population proportions\n",
    "p_normal_bike = 0.60\n",
    "p_e_bike = 0.40\n",
    "\n",
    "# Adjust counts based on proportions\n",
    "total_counts = np.array(normal_bike_counts) + np.array(e_bike_counts)\n",
    "expected_normal_bike_counts = total_counts * p_normal_bike\n",
    "expected_e_bike_counts = total_counts * p_e_bike\n",
    "\n",
    "# Create contingency table with expected counts\n",
    "contingency_table = np.array([normal_bike_counts, e_bike_counts])\n",
    "expected_table = np.array([expected_normal_bike_counts, expected_e_bike_counts])\n",
    "\n",
    "# Perform Chi-Square test with expected frequencies\n",
    "chi2_stat, p_val, dof, ex = chi2_contingency(contingency_table, correction=False)\n",
    "\n",
    "print(f'Chi2 Statistic: {chi2_stat}, P-value: {p_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA for age group distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  sum_sq   df         F    PR(>F)\n",
      "age_group  124355.609392  3.0  2.426782  0.140594\n",
      "Residual   136648.000000  8.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Example data with different sample sizes\n",
    "data = {\n",
    "    'distance': [29, 81, 116, 67, 361, 340, 161, 458, 403, 14, 250, 175 ],\n",
    "    'age_group': ['Age_Group_1', 'Age_Group_1', 'Age_Group_1',  \n",
    "                  'Age_Group_2', 'Age_Group_2', 'Age_Group_2',  \n",
    "                  'Age_Group_3', 'Age_Group_3', 'Age_Group_3', \n",
    "                  'Age_Group_4', 'Age_Group_4', 'Age_Group_4']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#WELCH ANOVA \n",
    "model = ols('distance ~ age_group', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2, robust='hc3')\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired T-Test and Logit Transformation for the Road Type Analysis\n",
    "#### mode, age, and gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapiroResult(statistic=0.9285017659902026, pvalue=0.5685824471769393),\n",
       " ShapiroResult(statistic=0.865789135939045, pvalue=0.2099297347390255),\n",
       " TtestResult(statistic=0.8684731850011399, pvalue=0.42485043706837294, df=5))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "data = {\n",
    "    \"Road Type\": [\"Cycleway\", \"Residential\", \"Primary\", \"Secondary\", \"Tertiary\", \"Unclassified\"],\n",
    "    \"E-bike\": [0.3152327221, 0.1636107193, 0.02820874471, 0.1488011283, 0.2475317348, 0.09661495063],\n",
    "    \"Standard Bicycle\": [0.3007975693, 0.204329662, 0.0140524117, 0.1344473984, 0.2628180782, 0.08355488036]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Logit Transformation\n",
    "df['logit_E-bike'] = np.log(df['E-bike'] / (1 - df['E-bike']))\n",
    "df['logit_Standard_Bicycle'] = np.log(df['Standard Bicycle'] / (1 - df['Standard Bicycle']))\n",
    "\n",
    "# Check for Normality using Shapiro-Wilk test\n",
    "shapiro_ebike = stats.shapiro(df['logit_E-bike'])\n",
    "shapiro_standard = stats.shapiro(df['logit_Standard_Bicycle'])\n",
    "\n",
    "# Perform paired t-test\n",
    "t_test_result = stats.ttest_rel(df['logit_E-bike'], df['logit_Standard_Bicycle'])\n",
    "\n",
    "# Output results\n",
    "shapiro_ebike, shapiro_standard, t_test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit Transformation for Ages and Road Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycleway: [-0.9108706645336643, -0.8686320026568548, -0.8578039009446883, -1.0003738492286691]\n",
      "Residential: [-1.8191584435904937, -1.8675195149588633, -1.813558697896492, -1.4280914898951143]\n",
      "Primary: [-4.852030263984117, -3.064169435048779, -3.1056768608250787, -3.536116699650717]\n",
      "Secondary: [-1.5817863808131485, -1.7596023575846216, -1.7386966238736872, -1.967650136007352]\n",
      "Tertiary: [-0.9108706645336643, -1.025587153890494, -1.0362346560594926, -1.2557978722342615]\n",
      "Unclassified: [-2.105874798571718, -2.038283469066011, -2.113791021647473, -1.620801671248677]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Cycleway\": [0.2868217054, 0.2955390335, 0.2977983778, 0.2688679245],\n",
    "    \"Residential\": [0.1395348837, 0.1338289963, 0.1402085747, 0.1933962264],\n",
    "    \"Primary\": [0.007751937984, 0.04460966543, 0.04287369641, 0.02830188679],\n",
    "    \"Secondary\": [0.1705426357, 0.1468401487, 0.1494785632, 0.1226415094],\n",
    "    \"Tertiary\": [0.2868217054, 0.2639405204, 0.2618771727, 0.2216981132],\n",
    "    \"Unclassified\": [0.1085271318, 0.1152416357, 0.1077636153, 0.1650943396]\n",
    "}\n",
    "\n",
    "# Function to perform logit transformation\n",
    "def logit(p):\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "# Apply logit transformation to the data\n",
    "logit_data = {road_type: [logit(p) for p in probabilities] for road_type, probabilities in data.items()}\n",
    "\n",
    "# Print the transformed data\n",
    "for road_type, transformed_probs in logit_data.items():\n",
    "    print(f\"{road_type}: {transformed_probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sum_sq    df         F    PR(>F)\n",
      "age_group   0.171805   3.0  0.053684  0.983131\n",
      "Residual   21.335341  20.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'road': [-0.91, -1.81, -4.852, -1.58, -0.91, -2.105,\n",
    "            -0.86, -1.86, -3.06, -1.56, -1.02, -2.03, \n",
    "            -0.857, -1.81, -3.105, -1.73, -1.03, -2.11, \n",
    "            -1.0, -1.42, -3.536, -1.96, -1.25, -1.62],\n",
    "    'age_group': ['Age_Group_1', 'Age_Group_1', 'Age_Group_1', 'Age_Group_1', 'Age_Group_1', 'Age_Group_1',\n",
    "                  'Age_Group_2', 'Age_Group_2', 'Age_Group_2',  'Age_Group_2',  'Age_Group_2','Age_Group_2',\n",
    "                  'Age_Group_3', 'Age_Group_3', 'Age_Group_3', 'Age_Group_3','Age_Group_3','Age_Group_3',\n",
    "                  'Age_Group_4', 'Age_Group_4', 'Age_Group_4','Age_Group_4', 'Age_Group_4', 'Age_Group_4']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#WELCH ANOVA \n",
    "model = ols('road ~ age_group', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2, robust='hc3')\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro men: ShapiroResult(statistic=0.8939977425632528, pvalue=0.33966649307330066), Shapiro women: ShapiroResult(statistic=0.8870948100097674, pvalue=0.30324449099575884), T-test P-value: TtestResult(statistic=0.15214920057090145, pvalue=0.8850181502962471, df=5)\n"
     ]
    }
   ],
   "source": [
    "# Normalized values\n",
    "\n",
    "data = {\n",
    "    \"Road Type\": [\"Cycleway\", \"Residential\", \"Primary\", \"Secondary\", \"Tertiary\", \"Unclassified\"],\n",
    "    'men': [0.310707457, 0.1787762906, 0.01912045889, 0.1496175908, 0.2543021033, 0.08747609943],\n",
    "    'women': [0.2966611932, 0.2074438971, 0.01915708812, 0.1308155446, 0.2621784346, 0.08374384236]\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Logit transformation \n",
    "df['logit_men'] = np.log(df['men'] / (1 - df['men']))\n",
    "df['logit_women'] = np.log(df['women'] / (1 - df['women']))\n",
    "\n",
    "# Check for Normality using Shapiro-Wilk test\n",
    "shapiro_men = stats.shapiro(df['logit_men'])\n",
    "shapiro_women = stats.shapiro(df['logit_women'])\n",
    "\n",
    "# Perform paired t-test\n",
    "t_test_result = stats.ttest_rel(df['logit_men'], df['logit_women'])\n",
    "\n",
    "# Output results\n",
    "print(f'Shapiro men: {shapiro_men}, Shapiro women: {shapiro_women}, T-test P-value: {t_test_result}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro rural: ShapiroResult(statistic=0.9125089714688732, pvalue=0.45310710952500893), Shapiro urban: ShapiroResult(statistic=0.803522477992112, pvalue=0.06320820719617136), T-test P-value: TtestResult(statistic=0.9762041457309291, pvalue=0.3737971149326715, df=5)\n"
     ]
    }
   ],
   "source": [
    "# Normalized values\n",
    "data = {\n",
    "     \"Road Type\": [\"Cycleway\", \"Residential\", \"Primary\", \"Secondary\", \"Tertiary\", \"Unclassified\"],\n",
    "    \"rural\": [0.2929465301, 0.1450511945, 0.03924914676, 0.1467576792, 0.2593856655, 0.1166097838], \n",
    "    \"urban\": [0.3132171696, 0.2239694008, 0.003824904377, 0.134721632, 0.2566935827, 0.06757331067]\n",
    "\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Logit transformation \n",
    "df['logit_rural'] = np.log(df['rural'] / (1 - df['rural']))\n",
    "df['logit_urban'] = np.log(df['urban'] / (1 - df['urban']))\n",
    "\n",
    "# Check for Normality using Shapiro-Wilk test\n",
    "shapiro_rural = stats.shapiro(df['logit_rural'])\n",
    "shapiro_urban = stats.shapiro(df['logit_urban'])\n",
    "\n",
    "# Perform paired t-test\n",
    "t_test_result = stats.ttest_rel(df['logit_rural'], df['logit_urban'])\n",
    "\n",
    "# Output results\n",
    "print(f'Shapiro rural: {shapiro_rural}, Shapiro urban: {shapiro_urban}, T-test P-value: {t_test_result}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Urbanity Chi Squared Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Weighted Chi Squared for Urbanity Level Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2 Statistic: 121.74299868410914, P-value: 2.2663885688981556e-25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#WEIGHTED CHI2\n",
    "\n",
    "# Data: [Urbanity 1, Urbanity 2, etc.]\n",
    "normal_bike_counts = [817, 208, 148, 114, 229]\n",
    "e_bike_counts = [349, 146, 108, 159, 258]\n",
    "\n",
    "# Population proportions\n",
    "p_normal_bike = 0.60\n",
    "p_e_bike = 0.40\n",
    "\n",
    "# Adjust counts based on proportions\n",
    "total_counts = np.array(normal_bike_counts) + np.array(e_bike_counts)\n",
    "expected_normal_bike_counts = total_counts * p_normal_bike\n",
    "expected_e_bike_counts = total_counts * p_e_bike\n",
    "\n",
    "# Create contingency table with expected counts\n",
    "contingency_table = np.array([normal_bike_counts, e_bike_counts])\n",
    "expected_table = np.array([expected_normal_bike_counts, expected_e_bike_counts])\n",
    "\n",
    "# Perform Chi-Square test with expected frequencies\n",
    "chi2_stat, p_val, dof, ex = chi2_contingency(contingency_table, correction=False)\n",
    "\n",
    "print(f'Chi2 Statistic: {chi2_stat}, P-value: {p_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Men and Women Urbanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chi square test of independece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared Statistic: 6.4839495463192245\n",
      "P-value: 0.16580450523265755\n",
      "Degrees of Freedom: 4\n",
      "Expected Frequencies: \n",
      "[[550.08975928 582.91024072]\n",
      " [166.53202774 176.46797226]\n",
      " [121.86454508 129.13545492]\n",
      " [125.26315789 132.73684211]\n",
      " [226.25051    239.74949   ]]\n",
      "We fail to reject the null hypothesis (no association between urbanity level and total points).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Creating the contingency table\n",
    "data = np.array([\n",
    "    [574, 559],  # Level 1\n",
    "    [171, 172],  # Level 2\n",
    "    [108, 143],   # Level 3\n",
    "    [120, 138],   # Level 4\n",
    "    [217, 249]    # Level 5\n",
    "])\n",
    "\n",
    "# Perform the Chi-Squared test\n",
    "chi2, p, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-Squared Statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(f\"Expected Frequencies: \\n{expected}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis (there is an association between urbanity level and total points).\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis (no association between urbanity level and total points).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Squared test of Independence for Rural vs Urban for Urbanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared Statistic: 928.1035537506363\n",
      "P-value: 1.3563609996323396e-199\n",
      "Degrees of Freedom: 4\n",
      "Expected Frequencies: \n",
      "[[595.2144242  583.7855758 ]\n",
      " [181.74486235 178.25513765]\n",
      " [131.7650252  129.2349748 ]\n",
      " [141.861962   139.138038  ]\n",
      " [251.41372625 246.58627375]]\n",
      "We reject the null hypothesis (there is an association between urbanity level and total points).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Creating the contingency table\n",
    "data = np.array([\n",
    "    [929, 250],  # Level 1\n",
    "    [208, 152],  # Level 2\n",
    "    [83, 178],   # Level 3\n",
    "    [49, 232],   # Level 4\n",
    "    [33, 465]    # Level 5\n",
    "])\n",
    "\n",
    "# Perform the Chi-Squared test\n",
    "chi2, p, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-Squared Statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(f\"Expected Frequencies: \\n{expected}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis (there is an association between urbanity level and total points).\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis (no association between urbanity level and total points).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters expected differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square Statistic: 21.673759745035312\n",
      "P-value: 0.7961663336480427\n",
      "Degrees of Freedom: 28\n",
      "Expected Frequencies:\n",
      " [[29.04657534  0.62465753 27.32876712]\n",
      " [15.28767123  0.32876712 14.38356164]\n",
      " [11.72054795  0.25205479 11.02739726]\n",
      " [11.2109589   0.24109589 10.54794521]\n",
      " [ 9.17260274  0.19726027  8.63013699]\n",
      " [17.3260274   0.37260274 16.30136986]\n",
      " [ 8.15342466  0.17534247  7.67123288]\n",
      " [ 8.15342466  0.17534247  7.67123288]\n",
      " [ 7.64383562  0.16438356  7.19178082]\n",
      " [34.65205479  0.74520548 32.60273973]\n",
      " [ 7.64383562  0.16438356  7.19178082]\n",
      " [ 6.11506849  0.13150685  5.75342466]\n",
      " [ 9.17260274  0.19726027  8.63013699]\n",
      " [ 5.60547945  0.12054795  5.2739726 ]\n",
      " [ 5.09589041  0.10958904  4.79452055]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Data provided\n",
    "data = {\n",
    "    \"clusterID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    \"men\": [27, 16, 9, 12, 10, 17, 10, 8, 8, 34, 8, 8, 10, 6, 3],\n",
    "    \"women\": [27, 14, 14, 10, 8, 17, 6, 8, 7, 34, 7, 4, 7, 5, 7],\n",
    "    \"other\": [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the contingency table\n",
    "contingency_table = pd.melt(df, id_vars=[\"clusterID\"], value_vars=[\"men\", \"women\", \"other\"], var_name=\"Gender\", value_name=\"Count\")\n",
    "contingency_table = contingency_table.pivot_table(index=\"clusterID\", columns=\"Gender\", values=\"Count\").fillna(0)\n",
    "\n",
    "# Perform the Chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-square Statistic:\", chi2)\n",
    "print(\"P-value:\", p)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected Frequencies:\\n\", expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
